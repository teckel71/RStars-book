# Análisis previo de datos.

![[Comandante de rogue one freight supervisando los datos de travesía.]{.smallcaps}](figuras/05%20la%20piloto.jpg){width="100%"}

## ![](figuras/book.svg){.hicon}![](figuras/pie-chart.svg){.hicon} Introducción.

Antes de la aplicación de técnicas complejas que permitan extraer de los datos conclusiones relevantes, es necesario realizar unas **tareas previas** destinadas a conseguir dos objetivos:

-   **Preparar nuestros datos** para que puedan ser procesados correctamente sin provocar distorsiones en los resultados. En especial, hay dos puntos clave: el tratamiento de los datos faltantes (***missing values***) y de los casos atípicos o ***outliers***.

-   Obtener una **visión inicial de la información** que esconden los datos, fundamentalmente en cuanto a las medidas básicas que caracterizan la distribución de frecuencias de las variables en las que se estructuran estos, y, en el caso de contar con más de una variable, de la relación estadística que existe entre ellas.

Además, es preciso tener en cuenta que, usualmente, es conveniente que estos rasgos iniciales que caracterizan a nuestra muestra o población sean plasmados de un modo **visualmente amigable**, claro y conciso.

En esta práctica, por medio de un ejemplo basado en una base de datos de las empresas dedicadas al transporte de mercancías interestelar, se mostrarán una serie de buenas prácticas y análisis básicos útiles a la hora de preparar y analizar inicialmente nuestro conjunto de datos.

Vamos a suponer que trabajamos dentro de un **proyecto** que hemos creado previamente, de nombre "explora". Dentro de la carpeta del proyecto guardaremos el *script* llamado "previo_rstars.R", y el archivo de Microsoft® Excel® llamado "interestelar_100.xlsx". Para decargar los ficheros, ve al final de este capítulo y pincha en los enlaces.

Si abrimos "interestelar_100.xlsx", comprobaremos que se compone de tres hojas. La primera muestra un aviso sobre el uso exclusivo que se debe dar a los datos incorporados; la segunda recoge la descripción de las variables consideradas; y la tercera (hoja "Datos") guarda los datos que debemos **importar** desde R-Studio. Estos datos se corresponden con diferentes variables económico-financieras y de diversa índole de una muestra de empresas que se dedican al transporte de mercancías interestelar.

Es muy importante observar que, en la hoja de cálculo, existen variables con datos faltantes (*missing values*). En concreto, podemos identificar estas faltas de dato por la presencia de celdas en blanco; pero también por la existencia de celdas con el texto, por ejemplo, "n.d." (no dato). Así, es clave identificar el modo en que quedan recogidos los datos faltantes en la hoja de cálculo, ya que **tendremos que aplicar código adicional** en el comando de importación de R **para que estos casos queden correctamente recogidos como *NAs*** (*not available*).

Cerraremos el archivo de Microsoft® Excel®, "interestelar_100.xlsx" y volveremos a RStudio. Después, abriremos nuestro *script* "previo_rstars.R" con `File → Open File…` Este *script* contiene el código que vamos a ir ejecutando en la práctica.

La primera línea / instrucción en el *script* es:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
## Tratamiento y análisis previo de datos.

# Limpiando el Global Environment
rm(list = ls())
```

La instrucción tiene como objeto limpiar el *Global Environment* (memoria) de objetos de anteriores sesiones de trabajo.

Luego, si queremos despreocuparnos de la carga de los paquetes que utilizaremos en el script, podemos activarlos ahora:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Cargando paquetes
library (readxl)
library (gtExtras)
library (dplyr)
library (visdat)
library (ggplot2)
library (knitr)
library (kableExtra)
library (moments) # paquete necesario para calcular la curtosis.
library (patchwork)
library (GGally)
```

Para importar los datos que hay en la hoja "Datos" del archivo de Microsoft® Excel® y hacer una primera inspección de las variables que contiene, ejecutaremos el código:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
## DATOS

# Importando datos desde Excel
interestelar_100 <- read_excel("interestelar_100.xlsx",
                               sheet = "Datos",
                               na = c("n.d."))
interestelar_100 <- data.frame(interestelar_100, row.names = 1)

# visualizando el data frame de modo elegante con {gtExtras}
datos_df_graph <- gt_plt_summary(interestelar_100)
datos_df_graph
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
## DATOS

# Importando datos desde Excel
interestelar_100 <- read_excel("interestelar_100.xlsx",
                               sheet = "Datos",
                               na = c("n.d."))
interestelar_100 <- data.frame(interestelar_100, row.names = 1)
```

Por defecto, R considera las celdas en blanco de la hoja de cálculo como NAs; pero hemos de advertirle del resto de posibilidades que existen en la hoja para comunicar que falta un dato determinado, como ya se ha comentado. Para ello, hemos añadido en la función `read_excel()` el argumento `na =`, que recoge los contenidos de celda de la hoja de cálculo que indican que falta el dato en cuestión.

Por otro lado, R ha considerado la primera columna como una variable categórica. En realidad, esta columna no es una variable, sino que está formada por los nombres de los diferentes casos u observaciones. Para evitar que R tome la columna de los nombres de los casos como una variable más, hemos redefinido nuestro *data frame* diciéndole que tome esa primera columna como el conjunto de los *nombres* de los casos (filas).

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# visualizando el data frame de modo elegante con {gtExtras}
datos_df_graph <- gt_plt_summary(interestelar_100)
datos_df_graph
```

En la "tabla" de variables obtenida, se comprueba que 24 variables son métricas, mientras que 4 son categóricas.

## ![](figuras/book.svg){.hicon}![](figuras/pie-chart.svg){.hicon} Análisis de una variable.

### ![](figuras/key.svg){.hicon} Buscando *missing values* y *outliers*.

Vamos a suponer que la variable que queremos estudiar es la variable *Rentabilidad Económica* (RENECO). Es una buena práctica el trabajar con una copia del data frame original. Con ello, conseguimos mantener la integridad del *data frame* original, y que el código sea fácilmente utilizable en otros scripts, al utilizar en la copia un nombre genérico. Utilizaremos la función `select()` con el argumento `everything()` del paquete `{dplyr}`:

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, message=FALSE}
# Copia de df
muestra<- select(interestelar_100, everything())
```

La primera acción que debe realizarse es comprobar que todos los casos (empresas) tienen su correspondiente dato o valor para la variable (RENECO), es decir, que no existen **valores perdidos o *missing values***.

Para tener una idea general, se puede utilizar la función `vis_miss()` del paquete `{visdat}`, que nos localizará gráficamente los *missing values* de las diferentes variables, y calculará el porcentaje de casos que supone, con respecto al total de observaciones. Para limitar el análisis solo a la variable RENECO, filtraremos de *data frame* con la función `select()` del paquete `{dplyr}`:

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, message=FALSE}
## Analisis de una variable.

# Localizando missing values.
muestra %>%
  select (RENECO) %>%
  vis_miss() +
    labs(title = "Rentabilidad Económica: valores ausentes",
      subtitle = "Transporte de mercancías interestelar",
      y = "Observación",
      fill = NULL) +
    scale_fill_manual(
      values = c("TRUE" = "red", "FALSE" = "grey"),
      labels = c("TRUE" = "NA", "FALSE" = "Presente")) +
  theme(
    plot.title = element_text(face = "bold", size = 14))
```

La explicación detallada del código es la siguiente:

-   **`muestra %>%:`** Usa el *pipe* de **dplyr** para encadenar operaciones de forma legible.

-   **`select(RENECO):`** Te quedas solo con la columna `RENECO`. Así, el gráfico se centra en esa variable (una sola columna en la visualización).

-   **`vis_miss():`** Función del paquete **visdat** que crea un mapa de celdas **Present/Missing**:

    -   Eje **Y** = observaciones (filas del data frame).

    -   Eje **X** = variables (aquí, solo `RENECO`).

    -   Cada celda indica si el valor está presente o es NA.

-   **`labs(...):`**

    -   `title` y `subtitle`: títulos del gráfico.

    -   `y = "Observación"`: etiqueta del eje Y.

    -   `fill = NULL`: **quita el título de la leyenda** (por defecto aparecería algo tipo “valueType” o similar).

-   **`scale_fill_manual(...):`** Personaliza los colores y las etiquetas de la leyenda:

    -   `values = c("TRUE" = "red", "FALSE" = "grey"):` En `vis_miss`, internamente se codifica si falta el dato (`TRUE`) o no (`FALSE`). Aquí dices: rojo para `TRUE` (hay NA) y gris para `FALSE` (dato presente).

    -   `labels = c("TRUE" = "NA", "FALSE" = "Presente"):` Cambias el texto mostrado en la leyenda: en lugar de `TRUE/FALSE`, se verá NA/Presente.

-   **`theme(plot.title = element_text(face = "bold", size = 14)):`** Pone el título en negrita y con tamaño 14.

Puede observarse cómo, en el caso concreto de la variable RENECO, un 1% (aproximadamente) de los casos no tienen dato (es decir, uno de los 104 casos). Para localizar el caso concreto, recurriremos a las herramientas de manejo de *data frames* del paquete `{dplyr}`. En concreto, filtraremos los casos para detectar aquellos que carecen de valor en la variable RENECO:

```{r eval=FALSE, echo=TRUE, message=FALSE}
# Mostrar casos concretos de NAs
muestra %>% filter(is.na(RENECO)) %>% select(RENECO)
```

La función `is.na()` comprueba si, en la posición correspondiente a una fila o caso, para la variable escrita en el argumento; hay o no un dato o valor. Como resultado se obtiene una empresa, para las que se puede comprobar que no hay valor para la variable RENECO:

```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
# Hacer copia del df y mostrar casos concretos de NAs
muestra %>% filter(is.na(RENECO)) %>% select(RENECO)
```

Comprobamos que la empresa sin valor en RENECO es "Photon Pack Freight".

Ante la existencia de *missing values*, se puede actuar de varios modos. Por ejemplo, se puede intentar obtener por otro canal de información el conjunto de valores de RENECO que no están disponibles, o recurrir a alguna estimación para los mismos y asignarlos. En caso de que esto sea difícil, se puede optar, simplemente, por eliminar estos casos, en especial cuando representan un porcentaje muy reducido respecto al total de casos. En nuestro ejemplo, vamos a suponer que hemos optado por esta última vía, al no conseguir unos valores más o menos verosímiles de RENECO para las empresas de las que se carece de dato. Esta **eliminación de casos** se podrá realizar mediante el código:

```{r, eval=TRUE, echo=TRUE}
muestra <- muestra %>% filter(! is.na(RENECO))
```

El operador **`!`** significa "no".

Podemos comprobar cómo en el *Global Environment* aparece el *data frame* "muestra" con un caso menos (103).

Una vez tratados los casos con valores perdidos o *missing values*, **conviene detectar la posible presencia en la muestra de *outliers*** o casos atípicos, que pudieran desvirtuar los resultados derivados de ciertos análisis. Al trabajar con una sola variable métrica (la rentabilidad económica, RENECO), podemos realizar esta tarea representando gráficamente la variable mediante un ***boxplot*** o *gráfico de caja*. Aplicaremos, por ejemplo, el código siguiente, que utiliza la gramática del paquete `{ggplot2}`:

```{r eval=FALSE, echo=TRUE, message=FALSE}
## Localizando outliers
ggplot(data = muestra, map = (aes(y = RENECO))) +
    geom_boxplot(fill = "orange") +
    ggtitle("Rentabilidad Económica",
            subtitle = "Empresas de transporte interestelar") +
            ylab("Rentabilidad Económica (%)") +
    theme(plot.title = element_text(face = "bold", size = 14))
```

Obteniéndose el gráfico:

```{r eval=TRUE, echo=FALSE, message=FALSE}
## Localizando outliers
ggplot(data = muestra, map = (aes(y = RENECO))) +
    geom_boxplot(fill = "orange") +
    ggtitle("Rentabilidad Económica",
            subtitle = "Empresas de transporte interestelar") +
            ylab("Rentabilidad Económica (%)") +
    theme(plot.title = element_text(face = "bold", size = 14))
```

La "caja" contiene el 50% de los valores de la variable que toman los casos centrales (los que van del primer cuartil al tercero, cuya diferencia se llama *rango intercuartílico*), y contiene una línea horizontal que es la mediana (segundo cuartil). Por arriba sobresale un segmento que llega al mayor valor de la variable que toma algún caso y que no llega a ser atípico; y por debajo de la caja otro segmento que llega al menor valor de la variable que toma algún caso y que no llega a ser atípico. Los casos atípicos o outliers son aquellos que toman valores que se alejan más de 1.5 veces del rango intercuartílico (altura de la caja) del tercer cuartil, por arriba; o del primer cuartil, por abajo. Se registran mediante puntos.

En nuestro caso, el *boxplot* ratifica la existencia de dos casos atípicos. Para identificar esos dos casos concretos, podemos recurrir al paquete `{dplyr}`, y **establecer un filtro** con el siguiente código:

```{r eval=FALSE, echo=TRUE, message=FALSE}
# Mostrar casos concretos de outliers
Q1 <- quantile (muestra$RENECO, c(0.25))
Q3 <- quantile (muestra$RENECO, c(0.75))

muestra %>% 
  filter(RENECO > Q3 + 1.5*IQR(RENECO) |
         RENECO < Q1 - 1.5*IQR(RENECO)) %>%
  select(RENECO)
```

En el código anterior, las dos primeras filas calculan los cuartiles primero (Q1) y tercero (Q3) mediante la función `quantile()`. En esta función, es preciso poner como segundo argumento la proporción de casos que van a quedar por debajo del "cuantil" en cuestión (por ejemplo, el primer cuartil se calcula poniendo 0.25, dado que deja por debajo al 25% de casos con menor valor en la variable). Luego se filtran los *outliers* mediante la función `filter()` de `{dplyr}` , calculados como aquellos casos con valores de RENECO mayores que Q3 más 1,5 veces el rango intercuartílico de la variable; o menores que Q1 menos 1,5 veces dicho rango intercuartílico. Para calcular el rango intercuartílico se recurre a la función `IQR()`. Finalmente, con `select()`, se muestran los casos en la consola de R-Studio:

```{r eval=TRUE, echo=FALSE, message=FALSE}
# Mostrar casos concretos de outliers
Q1 <- quantile (muestra$RENECO, c(0.25))
Q3 <- quantile (muestra$RENECO, c(0.75))

muestra %>% 
  filter(RENECO > Q3 + 1.5*IQR(RENECO) |
         RENECO < Q1 - 1.5*IQR(RENECO)) %>%
  select(RENECO)
```

Los casos atípicos o *outliers* en la variable RENECO son "Jovian Logistics" y "Sandworm Freight".

Como ocurría con los *missing values*, el **tratamiento de los *outliers*** depende de la información que se tenga, y del enfoque que se quiera seguir en la aplicación de las diferentes técnicas, existiendo varias alternativas (corrección del dato, estimación, eliminación del caso, mantenimiento del caso tal y como está y utilización de *técnicas robustas*, etc.) Es un tema que a veces resulta **complejo**, y que no está exento de divergencias en la opinión de los investigadores.

Por tanto, una opción posible es, si no se tiene información fiable y los *outliers* no representan una gran proporción respecto al total de casos, la eliminación de los casos que presentan valores atípicos en las variables en estudio. En este ejemplo, efectivamente, **eliminaremos estas dos empresas con comportamiento atípico** en la rentabilidad económica (RENECO), a fin de que su presencia en la muestra **no** **distorsione los resultados en la aplicación posterior de ciertas técnicas** (por ejemplo, un ANOVA o un análisis de regresión). Podemos hacerlo creando un nuevo *data frame* a partir de "muestra"; pero sin esos dos casos. Ese nuevo *data frame* se llamará, por ejemplo, "muestra_so":

```{r eval=TRUE, echo=TRUE, message=FALSE}
# Eliminar outliers
muestra_so <- muestra %>%
              filter(RENECO <= Q3 + 1.5*IQR(RENECO) &
                     RENECO >= Q1 - 1.5*IQR(RENECO))
```

Es importante observar que, en el código de la función `filter()`, las desigualdades deben cambiar, así como el operador "**\|**" por el operador "**&**". En el *Global Environment* podemos comprobar cómo el *data frame* "muestra_so" posee el mismo número de variables que el *data frame* "muestra"; pero con dos observaciones o casos menos (101).

### ![](figuras/key.svg){.hicon} Descripción de una variable.

Una vez que se tiene preparada la base de datos, con un tratamiento adecuado de los *missing values* y de los *outliers,* y **antes** de proceder a la aplicación de una técnica adecuada según los objetivos perseguidos en el estudio; suelen presentarse una serie de **gráficos** básicos y **medidas** descriptivas que proporcionan una **idea inicial de la estructura** del sector para la variable o variables analizadas. Nos referimos a medidas y/o gráficos de posición, dispersión y forma (asimetría y curtosis).

Antes de ello, es conveniente presentar una tabla donde se recoja la distribución de frecuencias de la variable. Si son muchos los casos (en el ejemplo, 101), la distribución podría presentarse agrupada en intervalos, como ya se vio en el capítulo 4 de este libro. De este modo, el código para generar la tabla podría ser (recordar que tienen que estar activas los paquetes `{knitr}` y `{kableExtra}`:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
# Tabla de datos (distribución de frecuencias agrupadas en intervalos)
# Colocando casos
muestra_so <- muestra_so %>% arrange(RENECO, row.names(muestra_so))

# Fijar k como número de intervalos (método de Sturges)
k <- nclass.Sturges(muestra_so$RENECO)

# Crear los intervalos
muestra_so$intervalos <- cut(muestra_so$RENECO, breaks = k, include.lowest = TRUE)

# Contar las frecuencias de cada intervalo
conteo_intervalos <- table(muestra_so$intervalos)

# Convertir el resultado a un data frame para una mejor visualización
conteo_intervalos_df <- as.data.frame(conteo_intervalos)

# Renombrar las columnas para mayor claridad
colnames(conteo_intervalos_df) <- c("Intervalo", "Frecuencia")

# Calcular y guardar la frecuencia total
N_agre <- sum(conteo_intervalos_df$Frecuencia)

# Calcular frecuencias absolutas acumuladas
conteo_intervalos_df$Frecuencia_acum <- cumsum(conteo_intervalos_df$Frecuencia)

# Calcular frecuencias relativas
conteo_intervalos_df$Frecuencia_R <- conteo_intervalos_df$Frecuencia / N_agre

# Calcular frecuencias relativas acumuladas
conteo_intervalos_df$Frecuencia_R_acum <- cumsum(conteo_intervalos_df$Frecuencia_R)

# Mostrar el resultado
conteo_intervalos_df %>%
  kable(caption = "Distribución de frecuencias agrupadas en intervalos de Rentabilidad Económica",
        col.names = c("Intervalo rentabilidad", "Frecuencia absoluta n(i)",
                      "Frecuencia absoluta acum. N(i)", "Frecuencia relativa f(i)",
                      "Frecuencia relativa acum. F(i)"),
        digits    = c(NA, 0, 0, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F, bootstrap_options = "striped",
                "bordered", "condensed",
                position = "center", font_size = 11) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(conteo_intervalos_df)), bold= F, align = "c")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# Tabla de datos (distribución de frecuencias agrupadas en intervalos)
# Colocando casos
muestra_so <- muestra_so %>% arrange(RENECO, row.names(muestra_so))

# Fijar k como número de intervalos (método de Sturges)
k <- nclass.Sturges(muestra_so$RENECO)

# Crear los intervalos
muestra_so$intervalos <- cut(muestra_so$RENECO, breaks = k, include.lowest = TRUE)

# Contar las frecuencias de cada intervalo
conteo_intervalos <- table(muestra_so$intervalos)

# Convertir el resultado a un data frame para una mejor visualización
conteo_intervalos_df <- as.data.frame(conteo_intervalos)

# Renombrar las columnas para mayor claridad
colnames(conteo_intervalos_df) <- c("Intervalo", "Frecuencia")

# Calcular y guardar la frecuencia total
N_agre <- sum(conteo_intervalos_df$Frecuencia)

# Calcular frecuencias absolutas acumuladas
conteo_intervalos_df$Frecuencia_acum <- cumsum(conteo_intervalos_df$Frecuencia)

# Calcular frecuencias relativas
conteo_intervalos_df$Frecuencia_R <- conteo_intervalos_df$Frecuencia / N_agre

# Calcular frecuencias relativas acumuladas
conteo_intervalos_df$Frecuencia_R_acum <- cumsum(conteo_intervalos_df$Frecuencia_R)
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}

# Mostrar el resultado
if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
conteo_intervalos_df %>%
  kable(caption = "Distribución de frecuencias agrupadas en intervalos de Rentabilidad Económica",
        col.names = c("Intervalo rentabilidad", "Frecuencia absoluta n(i)",
                      "Frecuencia absoluta acum. N(i)", "Frecuencia relativa f(i)",
                      "Frecuencia relativa acum. F(i)"),
        digits    = c(NA, 0, 0, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F, bootstrap_options = "striped",
                "bordered", "condensed",
                position = "center", font_size = 11) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(conteo_intervalos_df)), bold= F, align = "c")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
conteo_intervalos_df %>%
  kable(caption = "Distribución de frecuencias agrupadas en intervalos de Rentabilidad Económica",
        col.names = c("Intervalo rentabilidad", "Frecuencia absoluta n(i)",
                      "Frecuencia absoluta acum. N(i)", "Frecuencia relativa f(i)",
                      "Frecuencia relativa acum. F(i)"),
        digits    = c(NA, 0, 0, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE))
}
```

En conjunto, la **rentabilidad económica** de estas empresas se concentra en valores **medios–altos**: la gran mayoría se mueve en torno al 50–60%, y dos de cada cuatro intervalos centrales (47,4–53,9 y 53,9–60,3) reúnen la mayor parte de los casos. En términos prácticos, alrededor de ocho de cada diez compañías quedan entre 41% y 66,8%, lo que sugiere un sector relativamente estable, con resultados parecidos entre sí. En los extremos hay pocas: apenas un 5% presenta rentabilidades muy bajas (por debajo del 34,5%) y sólo un 2% llega a niveles muy altos (por encima del 73,2%). Económicamente, esto indica que la competencia y la eficiencia operativa tienden a “empujar” a las empresas hacia un rendimiento **razonable y sostenido**, mientras que los casos de fracaso o de éxito excepcional son **minoría**.

Por otro lado, el **análisis gráfico** suele dar una idea atractiva e intuitiva de la estructura de la distribución de frecuencias de nuestro conjunto de casos en relación con la variable a analizar.

Un gráfico fundamental es el **histograma** de la variable estudiada. Para ello, utilizaremos la gramática del paquete `{ggplot2}`:

```{r eval=TRUE, echo=TRUE, message=FALSE}
## Descriptivos básicos

# Gráficos básicos

g1 <-
ggplot(data = muestra_so, map = aes(x = RENECO)) +
  geom_histogram(bins = k,      #k es el número de intervalos de la tabla anterior
                 colour = "red",
                 fill = "orange",
                 alpha = 0.7) +
  geom_vline(xintercept = mean(muestra_so$RENECO),
             color = "dark blue",
             size = 1.2,
             alpha = 0.8) +
  ggtitle("Histograma")+
  xlab("Rentabilidad Económica (%)") +
  ylab("Frecuencias")

g1
```

En el gráfico vemos de un modo nítido la distribución de frecuencias en cuanto a la rentabilidad económica (RENECO). Se ha incorporado una línea vertical azul (mediante `geom_vline()`) para localizar la rentabilidad media. Entre otras cosas, se puede apreciar que la distribución de frecuencias es acampanada y prácticamente simétrica.

Como complemento al histograma, podemos realizar un gráfico de densidad de RENECO, al que añadiremos una curva normal con la misma media y desviación típica que nuestra distribución de frecuencias, y que se añade mediante `stat_function()` y el argumento `fun = dnorm`. Este gráfico representa la distribución de probabilidad empírica de la muestra, es una especie de histograma "suavizado". De este modo, se podrán verificar de un modo fácil algunas de las características avanzadas con la observación del histograma, como la asimetría positiva. El código es:

```{r eval=TRUE, echo=TRUE, message=FALSE}
g2 <-
ggplot(data = muestra_so, map = aes(x = RENECO)) +
  geom_density(colour = "red",
               fill = "orange",
               alpha = 0.7) +
  geom_vline(xintercept = mean(muestra_so$RENECO),
             color = "dark blue",
             size = 0.8,
             alpha = 0.8) +
  stat_function(fun = dnorm, args = list(mean = mean(muestra_so$RENECO),
                                         sd = sd(muestra_so$RENECO)),
                                         geom = "area",
                                         color = "darkblue", 
                                         fill = "yellow",
                                         alpha = 0.2) +
  ggtitle("Gráfico de densidad vs curva normal")+
  xlab("Rentabilidad Económica (%)") +
  ylab("Densidad")

g2
```

La curva naranja muestra cómo se distribuye la **rentabilidad económica**: tiene forma de “campana”, con la mayoría de empresas concentradas alrededor del 50–60%. La línea vertical azul marca el valor central (media), en torno al 52%. Comparada con la curva azul de referencia (la normal), la distribución real es muy parecida, aunque algo más ancha y con un ligero peso extra en rentabilidades algo por debajo del centro; en el extremo alto hay menos casos de lo que predeciría una campana perfecta. En términos económicos: el sector muestra un rendimiento **bastante estable** y similar entre compañías, con **pocas** muy rezagadas o extraordinariamente rentables.

Un tercer gráfico útil es el ***box-plot*** una vez se eliminaron los casos *outliers*, con la incorporación de los valores que toman los casos que componen la muestra, para lo cuál se utiliza el `geom_jitter`:

```{r eval=TRUE, echo=TRUE, message=FALSE}
g3 <-
ggplot(data = muestra_so, map = (aes(x = "", y = RENECO))) +
  geom_boxplot(color = "red",
               fill = "orange",
               outlier.shape = NA) +
  stat_summary(fun = "mean",
               geom = "point",
               size = 3,
               col = "darkblue") +
  geom_jitter(width = 0.1,
              size = 1,
              col = "darkred",
              alpha = 0.50) +
  ggtitle("Box-Plot") +
  ylab("Rentabilidad Económica (%)")

g3
```

El *box-plot* confirma que la rentabilidad económica está bastante concentrada en la zona central. La **mediana** ronda el **50%** (línea dentro de la caja) y la mitad de las empresas cae aproximadamente entre 46% y 59% (altura de la caja, IQR), lo que sugiere variabilidad moderada. El rombo azul (media) está muy cerca de la mediana, indicando casi simetría. Los bigotes se extienden hacia valores en torno a 35–70% y aparecen pocos outliers tanto por abajo (≈30%) como por arriba (hasta ≈80%). En términos económicos: la mayoría de compañías rinde de forma similar y estable alrededor del 50–60%, con casos extremos poco frecuentes.

Por otro lado, conviene tener conocimiento del valor de las principales **medidas descriptivas** (de posición, dispersión, forma) que caracterizan a la distribución de la variable a analizar. Para ello, vamos a crear un *data frame* llamado, por ejemplo, "estadisticos", que recogerá las diferentes medidas, calculadas al aplicar a la variable RENECO del *data frame* "muestra_so" la función de `{deplyr}` llamada `summarise()`. Se calcularán la media, desviación típica, valor mínimo, mediana, valor máximo, el coeficiente de asimetría de Fisher, y el coeficiente de apuntamiento o curtosis de Fisher. Precisamente, para poder calcular esta última medida, es preciso activar el paquete `{moments}`, que contiene la función `kurtosis()`. La versión del coeficiente de apuntamiento de esta función dispone como distribución perfectamente mesocúrtica el valor de 3, por lo que se le restará 3 en la versión que manejaremos para que la distribución mesocúrtica se sitúe en un coeficiente de 0. El código es:

```{r eval=TRUE, echo=TRUE, message=FALSE}
# Calcular estadísticos
estadisticos <- muestra_so %>% summarise( Media = mean(RENECO),
                                          DT = sd(RENECO),
                                          Mínimo = min(RENECO),
                                          Mediana = median(RENECO),
                                          Maximo = max(RENECO),
                                          Asimetria = skewness(RENECO),
                                          Curtosis = kurtosis(RENECO) - 3)
```

La ventaja de volcar las medidas y estadísticos en el *data frame* (de un solo caso) "estadisticos" es que se pueden mostrar los valores en una tabla elegante generada a partir de el mismo mediante las funciones `knitr()` y `kableExtra()`, como ya sabemos:

```{r eval=FALSE, echo=TRUE, message=FALSE}
# Mostrar estadisticos
estadisticos %>%
  kable(caption = "Principales Estadísticos de la Rentabilidad Económica",
        col.names = c("Media", "Mediana",
                      "Desviación Típica", "Valor mínimo",
                      "Valor Máximo", "C. Asimetría Fisher",
                      "C. Curtosis Fisher"),
        digits    = c(2, 2, 2, 2, 2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F, bootstrap_options = "striped",
                "bordered", "condensed",
                position = "center", font_size = 11) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(estadisticos)), bold= F, align = "c")
```

```{r eval=TRUE, echo=FALSE, message=FALSE}
# Determinar el formato de salida actual
output_format <- knitr::opts_knit$get("rmarkdown.pandoc.to")

# Formatear la tabla según el formato de salida
if (output_format == "html") {
  estadisticos %>%
  kable(caption = "Principales Estadísticos de la Rentabilidad Económica",
        col.names = c("Media", "Mediana",
                      "Desviación Típica", "Valor mínimo",
                      "Valor Máximo", "C. Asimetría Fisher",
                      "C. Curtosis Fisher"),
        digits    = c(2, 2, 2, 2, 2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F, bootstrap_options = "striped",
                "bordered", "condensed",
                position = "center", font_size = 11) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(estadisticos)), bold= F, align = "c")
} else if (output_format == "latex") {
estadisticos %>%
  kable(caption = "Principales Estadísticos de la Rentabilidad Económica",
        col.names = c("Media", "Mediana",
                      "Desviación Típica", "Valor mínimo",
                      "Valor Máximo", "C. Asimetría Fisher",
                      "C. Curtosis Fisher"),
        digits    = c(2, 2, 2, 2, 2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE))
}  
```

La interpretación de estas medidas fueron comentadas en el capítulo 4. En general, puede decirse que:

-   La rentabilidad típica del sector está en torno al 51–52% (media ≈ 51,6% y mediana ≈ 50,4%), lo que indica un nivel medio-alto y sin sesgos fuertes.

-   La variabilidad es moderada (desv. típica ≈ 10 p.p.): la mayoría de empresas se mueve, grosso modo, entre \~42% y \~62%. Es un sector relativamente estable.

-   La asimetría ligeramente positiva (0,14) sugiere que hay algunas compañías con rentabilidades algo superiores a lo habitual, pero no dominan el panorama.

-   La curtosis negativa (−0,19, platicúrtica) implica una distribución más “plana” que la normal: menos extremos (tanto muy altos como muy bajos) y también algo menos de concentración en el centro. Económicamente: hay diversidad razonable de resultados, pero pocos casos extremos de fracaso o de éxito extraordinario.

-   Los extremos observados (≈ 28% mínimo y ≈ 80% máximo) existen, pero son minoría.

-   **Conclusión:** el negocio de transporte interestelar muestra una **rentabilidad sostenida y relativamente homogénea**; hay diferencias entre empresas (gestión, escala, rutas, mix tecnológico), pero el **riesgo de resultados extremos** parece **contenido**, y los “superéxitos” son poco frecuentes.

### ![](figuras/key.svg){.hicon} Normalidad.

En muchas técnicas multivariantes basadas en métodos inferenciales (por ejemplo, análisis de la varianza, o en la regresión lineal), se requiere que las variables sigan una **distribución normal**. Para comprobarlo, se puede a recurrir a análisis gráficos o a análisis formales, estos últimos basados en contrastar la hipótesis nula de normalidad.

Vamos a mostrar un **método gráfico** muy extendido. Comprobaremos la normalidad de la variable RENECO mediante un ***gráfico qq*** (cuantil-cuantil), que compara los cuantiles de nuestra muestra con los de una distribución normal teórica (con la misma media y desviación típica). Si los puntos se sitúan cercanos a la diagonal, entonces se asumirá un comportamiento (aproximadamente) normal. El código para realizar el gráfico con las herramientas del paquete `{ggplot2}` es:

```{r eval=FALSE, echo=TRUE, message=FALSE}
## Normalidad

# Grafico QQ
g4 <-
ggplot(data = muestra_so, aes(sample = RENECO)) +
  stat_qq(colour = "red") + 
  stat_qq_line(colour = "dark blue") +
  ggtitle("QQ-Plot")

g4
```

Y el resultado:

```{r eval=TRUE, echo=FALSE, message=FALSE}
## Normalidad

# Grafico QQ
g4 <-
ggplot(data = muestra_so, aes(sample = RENECO)) +
  stat_qq(colour = "red") + 
  stat_qq_line(colour = "dark blue") +
  ggtitle("QQ-Plot")

g4
```

A veces, es difícil obtener una conclusión sólida con el gráfico *qq*; aunque en el ejemplo la separación de los puntos respecto al eje diagonal induce a pensar en que podría seguirse una distribución normal.

Si queremos ser más precisos, en lugar de un análisis gráfico se puede recurrir a realizar un análisis formal, basado en la realización de **contrastes de hipótesis**. Una prueba muy usual es la **prueba de normalidad de *Shapiro y Wilk***, que tiene un buen comportamiento en muestras relativamente reducidas. En esta prueba, la hipótesis nula equivale al supuesto de normalidad. Para un 5% de significación estadística, un p-valor superior a 0.05 implicará el no-rechazo de la hipótesis de normalidad. Para realizar la prueba, se ejecutará el código:

```{r eval=FALSE, echo=TRUE, message=FALSE}
# Prueba de Shapiro-Wilk

shapiro.test(x = muestra_so$RENECO)
```

El resultado obtenido en la consola es:

```{r eval=TRUE, echo=FALSE, message=FALSE}
# Prueba de Shapiro-Wilk

shapiro.test(x = muestra_so$RENECO)
```

Como el p-valor es (muy) superior a 0.05, **no se rechaza la hipótesis nula de normalidad en la distribución**, lo que implica que, para una significación estadística del 5%, la muestra apoya la hipótesis de que RENECO sigue un comportamiento normal, como ya se anticipó con el gráfico *qq*.

### ![](figuras/paperclip.svg){.hicon} Resumen: los 4 gráficos básicos en la descripción de una variable.

En definitiva, para describir de un modo inicial una distribución de frecuencias de una variable (en escala métrica), podrían analizarse los 4 gráficos que se han comentado anteriormente. Estos gráficos se pueden presentar conjuntamente, para ahorrar espacio en un informe, utilizando el paquete `{patchwork}`, que permite combinar e integrar en una sola imagen varios gráficos generados con `{ggplot2}`. En nuestro ejemplo, vamos a generar una figura que integra los 4 gráficos anteriores (que hemos denominado "g1", "g2", "g3" y "g4"). Para ello creamos el objeto "resumen", que integra los gráficos, mediante una asignación con la sintaxis del paquete `{patchwork}`: El operador `/` indica que los gráficos siguientes se dispondrán inmediatamente debajo; mientras que `|` indica que el gráfico siguiente se dispone al lado del anterior. Luego, se le añade también un título y un subtítulo personalizados:

```{r eval=TRUE, echo=TRUE, message=FALSE}
## Resumen gráfico

resumen <- (g1 | g2)/(g3 | g4)
resumen <- resumen + 
  plot_annotation(
    title = "Rentabilidad Económica",
    subtitle = "Empresas TMI (sin outliers)",
    theme = theme(
      # TÍTULO de la composición
      plot.title = element_text(
        size = 16,          # tamaño
        face = "bold",      # negrita
      ),
      # SUBTÍTULO de la composición
      plot.subtitle = element_text(
        size = 12
      )))
resumen
```

La composición gráfica se guarda en el *Global Environment* con el nombre "resumen". El bloque `plot_annotation()` determina y caracteriza el título y subtítulo del conjunto de gráficos.

## ![](figuras/book.svg){.hicon}![](figuras/pie-chart.svg){.hicon} Análisis de múltiples variables.

Son muchas las técnicas aplicadas al análisis de datos económicos basadas en una distribución de frecuencias multivariante. En este apartado nos centraremos en el caso de **variables métricas**, ya que al caso de atributos, variables categóricas o factores; le dedicaremos un capítulo en exclusiva. Algunas técnicas multivariantes son: el análisis de componentes principales, el análisis de regresión o el análisis clúster...

Todas estas metodologías requieren, de nuevo, de una fase inicial que ponga a punto la base de datos y ofrezca una fotografía de cómo es la situación en cuanto a las variables en estudio. En este sentido, es conveniente aplicar, para cada variable por separado, algunos de los análisis gráficos básicos vistos anteriormente.

A estos análisis básicos hay que añadir, principalmente, algún análisis previo adicional, destinado fundamentalmente a cuantificar el **grado de intensidad en la relación estadística** entre las variables implicadas, mediante el estudio de la ***correlación***. Antes de abordar esta cuestión, hemos de pararnos en una casuística específica que se presenta cuando trabajamos con numerosas variables: la detección de casos atípicos o *outliers*.

### ![](figuras/key.svg){.hicon} Localización de *missing values* y *outliers*.

Para trabajar con múltiples variables, en primer lugar es preciso localizar los casos con **valores perdidos o *missing values***, para decidir cómo procesarlos (eliminación del caso, estimación del valor faltante, etc.)

Vamos a imaginar que queremos realizar un análisis en el que tendremos en cuenta las variables RENECO (rentabilidad económica), ACTIVO (volumen de activos de la empresa), MARGEN (margen de beneficio) y RES (resultado del ejercicio).

En primer lugar, generaremos una copia del *data frame* original, "interestelar_100", para preservar su integridad. A esa copia la hemos llamado "muestra2". Ya vimos cómo el siguiente código nos aporta gráficamente una idea de la posible existencia de valores faltantes:

```{r echo=TRUE, message=FALSE, warning=FALSE, message=FALSE}
## Trabajando con multiples variables.

# Copia de df original.
muestra2<- select(interestelar_100, everything())

# Localizando missing values.
muestra2 %>%
  select (RENECO, ACTIVO, MARGEN, RES) %>%
  vis_miss() +
    labs(title = "Rentabilidad Económica: valores ausentes",
      subtitle = "Transporte de mercancías interestelar",
      y = "Observación",
      fill = NULL) +
    scale_fill_manual(
      values = c("TRUE" = "red", "FALSE" = "grey"),
      labels = c("TRUE" = "NA", "FALSE" = "Presente")) +
  theme(
    plot.title = element_text(face = "bold", size = 14))
```

Podemos apreciar cómo existen varios casos con *missing values* en las variables objeto de estudio.

Para localizar los casos concretos con *missing values*, podemos recurrir al siguiente código. En él, hemos sometido a "muestra2" a un *filtro* para detectar los casos en los que no hay valor para alguna (o varias) de las variables analizadas. El operador **`|`** significa "o". Posteriormente, hemos decidido eliminar esos casos (podría obtarse por otro tipo de tratamiento, como la estimación de valores). Para ello asignamos a "muestra2" el resultado de pasar un filtro en el que se eligen los casos que no tienen valores faltantes en ninguna de las variables. El operador **`&`** significa "y":

```{r eval=TRUE, echo=TRUE, message=FALSE}
## Trabajando con multiples variables.

# Localizando y descartando casos con missing values.
muestra2 %>% filter(is.na(RENECO) |
                      is.na(ACTIVO) |
                      is.na(MARGEN) |
                      is.na(RES))%>%
             select(RENECO, ACTIVO, MARGEN, RES)
muestra2 <- muestra2 %>%
            filter(! is.na(RENECO) &
                     ! is.na(ACTIVO) &
                     ! is.na(MARGEN) &
                     ! is.na(RES))
```

El *data frame* "muestra2" contiene los mismos datos que "interestelar_100", salvo los 3 casos con *missing values* que han sido eliminados (101): "Vega Transport", "Photon Pack Freight" y "Poe Dameron Cargo".

Para la **detección de *outliers***, si las variables que entran en el análisis son numerosas, podría ser poco operativo estudiar las variables una a una. Una alternativa consiste en calcular la ***distancia de Mahalanobis*** de las variables del estudio, como **"resumen" del comportamiento de cada caso** en todas las variables del análisis, consideradas conjuntamente. En concreto, se puede considerar como una suerte de “z-score multivariante”: mide cuántas desviaciones típicas se aleja una observación del “centro” del conjunto, teniendo en cuenta todas las variables a la vez y cómo se relacionan entre sí.

Su utilización, intuitivamente, se puede justificar de este modo:

-   Con una sola variable, el “raro” es el que está a muchos **z-scores** de la media.

-   Con varias variables (p. ej., rentabilidad, activo, margen, resultado), el “centro” es el vector de medias y la forma de la nube viene dada por la covarianza (las variables pueden estar en escalas distintas y estar correlacionadas).

-   La *distancia de Mahalanobis:*

    -   **Estandariza** las escalas (una variable en millones no pesa más que otra en porcentajes).

    -   **Gira y estira** el espacio según las correlaciones (si dos variables están muy correlacionadas, moverte a lo largo de su diagonal “cuesta” menos que moverte perpendicularmente).

-   En 2D lo verías como **elipses** alrededor del centro (no círculos). Los puntos fuera de la elipse “grande” son **potenciales *outliers***.

La distancia de Mahalanobis de un vector $\mathbf{x}\in\mathbb{R}^p$ respecto del centro $\boldsymbol{\mu}$ y la matriz de covarianzas $\mathbf{\Sigma}$ es:

$$
D_M(\mathbf{x})
= \sqrt{(\mathbf{x}-\boldsymbol{\mu})^{\top}\,\mathbf{\Sigma}^{-1}\,(\mathbf{x}-\boldsymbol{\mu})}.
$$

Así, primero vamos a calcular una columna más en el *data frame* "muestra2" con los valores de la *distancia de* *Mahalanobis* del conjunto de las 4 variables en cada uno de los casos. Esta columna o variable la denominaremos, por ejemplo, MAHALANOBIS*.* Para ello, se utiliza las funciones `mutate()` y `pick()` del paquete `{dplyr}`, y como argumento de esta la función `mahalanobis()`, en la que hay que especificar:

-   Las columnas de "muestra2" para las que se van a calcular las distancias.

-   El vector de medias de las variables para las que se calcula la distancia (argumento `center =`).

-   La matriz de varianzas y covarianzas de las variables para las que se calcula la distancia (argumento `cov =`).

En definitiva, el código es:

```{r eval=TRUE, echo=TRUE, message=FALSE}
# Identificando y descartando outliers con distancia de Mahalanobis.
muestra2 <- muestra2 %>%
  mutate(
    MAHALANOBIS = {
      X <- pick(RENECO, ACTIVO, MARGEN, RES)
      mahalanobis(as.matrix(X),
                  center = colMeans(X),
                  cov = cov(X))
    }
  )
```

Posteriormente, se puede construir el diagrama de caja de la variable MAHALANOBIS, como cualquier otra variable:

```{r eval=TRUE, echo=TRUE, message=FALSE}
ggplot(data = muestra2, map = (aes(y = MAHALANOBIS))) +
    geom_boxplot(fill = "orange") +
    ggtitle("DISTANCIA DE MAHALANOBIS",
            subtitle = "RENECO, ACTIVO, MARGEN, RES. Empresas TMI.") +
    ylab("MAHALANOBIS")
```

Se observa cómo existen varios casos *outliers*. Para saber de qué casos concretos se trata, se podrá ejecutar el código:

```{r eval=FALSE, echo=TRUE, message=FALSE}
Q1M <- quantile (muestra2$MAHALANOBIS, c(0.25))
Q3M <- quantile (muestra2$MAHALANOBIS, c(0.75))

muestra2 %>%
  filter(MAHALANOBIS > Q3M + 1.5*IQR(MAHALANOBIS) |
         MAHALANOBIS < Q1M - 1.5*IQR(MAHALANOBIS))%>%
  select(MAHALANOBIS, RENECO, ACTIVO, MARGEN, RES) 
```

En la consola se obtendrá el listado:

```{r eval=TRUE, echo=FALSE, message=FALSE}
Q1M <- quantile (muestra2$MAHALANOBIS, c(0.25))
Q3M <- quantile (muestra2$MAHALANOBIS, c(0.75))

df <- muestra2 %>%
  filter(MAHALANOBIS > Q3M + 1.5*IQR(MAHALANOBIS) |
           MAHALANOBIS < Q1M - 1.5*IQR(MAHALANOBIS))%>%
           select(MAHALANOBIS, RENECO, ACTIVO, MARGEN, RES)
  
# Número de columnas por bloque
columnas_por_bloque <- 3

# Dividir las columnas en bloques y mostrar los datos en la consola
for (i in seq(1, ncol(df), columnas_por_bloque)) {
  print(df[, i:min(i + columnas_por_bloque - 1, ncol(df))])
  cat("\n")
}
rm(i)
rm(df)
rm(columnas_por_bloque)
```

Si se opta por eliminar estos casos cara al análisis a aplicar posteriormente, se podrá crear un nuevo *data frame*, por ejemplo "muestra2_so", con el código siguiente:

```{r eval=TRUE, echo=TRUE, message=FALSE}
muestra2_so <- muestra2 %>%
  filter(MAHALANOBIS <= Q3M + 1.5*IQR(MAHALANOBIS) &
           MAHALANOBIS >= Q1M - 1.5*IQR(MAHALANOBIS)) 
```

El *data frame* "muestra2_so" será una réplica de "muestra2", aunque sin incluir los casos detectados como atípicos o *outliers* (91 casos).

### ![](figuras/key.svg){.hicon} Correlación entre variables.

Cuando trabajamos con más de una variable, una característica muy importante viene dada por la intensidad con la que tales variables están relacionadas estadísticamente entre sí, es decir, el estudio de las correlaciones. Un modo atractivo y rápido de visualizar la **matriz de correlaciones** de las variables es a través de la función `ggpairs()` del paquete `{GGally}`. Para aplicar la función, hemos creado el *data frame* "temporal" con las variables (métricas) del estudio, que borramos tras general el gráfico:

```{r eval=TRUE, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
## Correlaciones entre variables.
temporal <- muestra2_so %>% select(RENECO, ACTIVO, MARGEN, RES)
corr_plot_so <- ggpairs(temporal, 
                        lower = list(continuous = wrap("cor",
                        size = 4.5,
                        method = "pearson",
                        stars = TRUE)),
                        title = "Matriz de Correlación (sin outliers)")
rm(temporal)
corr_plot_so
```

La interpretación detallada del código es la siguiente:

-   **`ggpairs(temporal)`**: crea una cuadrícula con una fila/columna por variable del data frame `temporal`.

    -   **Triángulo inferior (`lower`)**: lo personalizamos para que muestre números de correlación.

-   **`lower = list(continuous = wrap("cor", ...))`**\
    En las celdas del triángulo inferior, cuando ambas variables son numéricas (“continuous”):

    -   **`"cor"`**: escribe el **coeficiente de correlación** entre esas dos variables.

    -   **`method = "pearson"`**: usa la correlación de *Pearson* (relación lineal).

    -   **`size = 4.5`**: tamaño del número que aparece.

    -   **`stars = TRUE`**: añade asteriscos de significación estadística junto al número. Habitual: `*` p \< 0.05, `**` p \< 0.01, `***` p \< 0.001 (más asteriscos ⇒ relación menos probable por azar).

-   **`title = "Matriz de Correlación sin outliers"`**: título del conjunto.

-   **Asignación `corr_plot_so <- ...`**: guarda la figura en el objeto `corr_plot_so`. Para verla, basta con escribir `corr_plot_so` en la consola.

Un coeficiente de correlación puede tomar un valor entre **-1** (fuerte relación, en sentido opuesto) y **+1** (fuerte relación, en el mismo sentido). Como puede apreciarse en el gráfico, las variables ACTIVO y RES mantienen una relación muy intensa y en sentido positivo. Entre MARGEN y RENECO existe también una relación de intensidad destacable. En cambio, ACTIVO y MARGEN; y RENECO y ACTIVO apenas están estadísticamente relacionadas.

Para finalizar, vamos a comparar las correlaciones anteriores con las que se dan si se incluyen los casos outliers en la muestra:

```{r eval=TRUE, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
temporal <- muestra2 %>% select(RENECO, ACTIVO, MARGEN, RES)
corr_plot_co <- ggpairs(temporal, 
                        lower = list(continuous = wrap("cor",
                                                       size = 4.5,
                                                       method = "pearson",
                                                       stars = TRUE)),
                        title = "Matriz de Correlación (con outliers)")
rm(temporal)
corr_plot_so_gg <- ggmatrix_gtable(corr_plot_so)
corr_plot_co_gg <- ggmatrix_gtable(corr_plot_co)

library (gridExtra)

grid.arrange(corr_plot_so_gg, corr_plot_co_gg, ncol = 2, top = "CORRELACIONES")
```

Puede observarse cómo la presencia de outliers puede variar la relación entre las variables. Salvo el caso de la correlación entre ACTIVO y RES, que se fortalece; las correlaciones entre RENECO y MARGEN, y RENECO y RES se debilitan. Esto redunda en la idea, ya expuesta, de que **la decisión de trabajar con o sin los casos *outliers*** es una cuestión, a veces, muy **relevante** y compleja.

## ![](figuras/arrow-down-circle.svg){.hicon} Materiales para realizar las prácticas del capítulo.

En esta sección se muestran los links de acceso a los diferentes materiales (scripts, datos...) necesarios para llevar a cabo los contenidos prácticos del capítulo.

**Datos (en formato Microsoft (R) Excel (R)):**

-   interestelar_100.xlsx ([obtener aquí](https://raw.githubusercontent.com/teckel71/RStars-book/main/download/trabajadores.xlsx))

**Scripts:**

-   previo_rstars.R ([obtener aquí](https://raw.githubusercontent.com/teckel71/RStars-book/main/download/previo_rstars.R))
