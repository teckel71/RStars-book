# Componentes principales.

![[Carguero a dos niveles de resolución.]{.smallcaps}](figuras/06%20carguero%20renderizado.jpg){width="100%"}

## ![](figuras/book.svg){.hicon} Introducción.

A veces, menos es más. Esta es la filosofía que subyace a las **técnicas de reducción de la dimensión** de la información.

Imaginemos una serie de casos (por ejemplo, las empresas de un sector económico) caracterizados por múltiples variables. Puede ocurrir que, paradójicamente, el contar con tantas variables haga difícil la caracterización de los casos. Esto ocurre cuando algunas de las variables aportan una información muy parecida sobre tales casos. Por ejemplo, es más difícil hacerse una idea del comportamiento global en el ámbito económico o financiero de un grupo de empresas si tenemos que atender a los valores que toman en un conjunto de 10 variables, que si solo tenemos que atender a un par de indicadores.

Las técnicas de reducción de la dimensión de la información tratan, precisamente, de disminuir el número de variables necesarias para caracterizar un grupo de casos, aprovechando la posibilidad de que las (múltiples) variables originales compartan información sobre estos. Es decir, la idea fundamental es pasar de un planteamiento basado en manejar muchas variables con información compartida o redundante (variables que "dicen lo mismo" sobre el comportamiento de los casos) a un planteamiento en el que hay **menos variables**, pero que **no comparten información** (variables que "dicen" cosas diferentes sobre el comportamiento de los casos). En este proceso es importante que la pérdida de información sea mínima, y que solo se pierda la información redundante o repetida.

La principal técnica de reducción de la dimensión de la información es la de **componentes principales,** y es la que se expondrá y ejemplificará en el resto del capítulo. Pero antes, es preciso concretar la relación entre dos conceptos muy presentes en esta técnica: información y varianza.

## ![](figuras/book.svg){.hicon} Información y varianza.

En el apartado anterior hemos hablado de la posibilidad de que algunas variables compartan "información" sobre el comportamiento de los casos que constituyen nuestra muestra u objeto de estudio. Pero, ¿qué es, en este contexto, la "información"?

La ***información*** que una variable contiene sobre un conjunto de casos puede entenderse como su **capacidad para diferenciar a unos casos de otros**.

Observemos este ejemplo, en el que se representan los valores que toman un grupo de 20 empresas en 3 variables.

![[Información y Varianza]{.smallcaps}](figuras/varianza.png){width="100%"}

En la variable 1, todas las empresas toman el mismo valor. Por tanto, la capacidad que tiene la variable para distinguir a los casos (empresas), unos de otros, es nula. Eso es debido a que, en definitiva, esta variable no contiene información sobre el grupo de 20 empresas.

En la variable 2, existe cierta dispersión, aunque reducida, en los valores que adoptan los casos. Esto permite distinguir a unos de otros, aunque a veces con cierta dificultad. Por ejemplo, la empresa 17 se distingue del resto por ser la que tiene un valor (un poco) mayor. Aun así, como la dispersión es reducida, no se distinguen algunos casos de otros demasiado bien. En definitiva, la variable 2 contiene cierta cantidad de información sobre el conjunto de empresas de la muestra, aunque no demasiado grande.

Por último, la variable 3 muestra una dispersión considerablemente mayor que las otras dos variables. Existe un amplio abanico de valores que toman los diferentes casos (empresas). Esto hace que puedan diferenciarse con facilidad, en general, unos de otros. Esta variable posee, por tanto, una cantidad de información superior respecto a las empresas, ya que observando los valores que toman en la variable pueden diferenciarse con facilidad unas de otras.

Como conclusión, podemos establecer que cuanto mayor dispersión muestra una variable para un grupo de casos, mayor cantidad de información contiene sobre ellos, en el sentido de disfrutar de un mayor "poder" de diferenciación de unos casos respecto a otros.

Una medida de la dispersión de una variable usualmente utilizada es la **varianza**. Por tanto, en cierta manera, la varianza sirve para medir la cantidad de información que contiene la variable: a mayor varianza, mayor dispersión. Y a mayor dispersión, mayor cantidad de información.

En el ejemplo, puede observarse cómo la variable 3 es la que mayor varianza tiene, luego la variable 2, y la variable 1 tiene una varianza de 0 (y no posee información sobre las 20 empresas). Esta comparación de varianzas es válida siempre y cuando las tres variables estén expresadas en las mismas unidades, ya que la varianza es una medida de dispersión absoluta. Por ello, para poder comparar, hemos añadido también en el ejemplo una medida de dispersión relativa: el coeficiente de variación. Podemos comprobar cómo el mayor coeficiente de variación pertenece a la variable 3 (que es la que tiene una mayor cantidad de información), luego la variable 2 (que cuenta con menor cantidad de información), y por último la variable 1, con un coeficiente de 0 (no contiene información sobre las empresas).

## ![](figuras/star.svg){.hicon} La elección de *Arg-Us Korp*.

Vamos a considerar el caso del sector del "Transporte Interestelar". Tenemos una selección de 104 empresas o compañías. El "magnate" de los negocios a escala interplanetaria, *Arg-us* *Korp* en la imagen), está de compras: quiere adquirir una de las empresas que mejor proyección a futuro en el sector tenga.

![[Arg-Us Korp.]{.smallcaps}](figuras/Arg-Us%20Korp.jpg){.d-block .mx-auto width="500"}

Hay varias variables disponibles que pueden ser interpretadas como *indicadores* de la preparación de las diferentes compañías de transporte para afrontar el futuro, como por ejemplo:

1.  **IMD (Gasto en I+D)**

    -   Justificación: Una inversión alta en investigación y desarrollo indica que la empresa está preparándose para innovaciones tecnológicas, lo que le permitirá mejorar su eficiencia, reducir costos y mantenerse competitiva en el futuro.

2.  **IDIG (Índice de Digitalización)**

    -   Justificación: La digitalización es un factor clave en la eficiencia operativa y la adaptabilidad a nuevas tecnologías. Un alto IDIG sugiere que la empresa está invirtiendo en automatización, software avanzado y optimización de procesos.

3.  **EFLO (Edad Media de la Flota)**

    -   Justificación: Contar con una flota renovada significa menor riesgo de fallas mecánicas, menores costos de mantenimiento y mayor eficiencia en las operaciones, lo que permite mantener ventajas competitivas a largo plazo.

4.  **CAPEX (Gastos de Capital)**

    -   Justificación: Empresas que invierten en infraestructura y equipamiento moderno están mejor preparadas para el crecimiento y la adaptación a nuevas demandas del mercado.

5.  **IDIVERSE (Índice de Diversificación)**

    -   Justificación: Empresas con operaciones diversificadas tienen mayor resiliencia ante cambios del mercado, ya que no dependen de una única fuente de ingresos o de un solo tipo de carga.

6.  **RUTAS (Número de Rutas Atendidas)**

    -   Justificación: La expansión de rutas refleja una empresa con visión de crecimiento y acceso a mercados emergentes, lo que fortalece su sostenibilidad a largo plazo.

7.  **SOLVENCIA**

    -   Justificación: Empresas con una solvencia alta tienen mayor capacidad de enfrentar crisis económicas o períodos de baja demanda sin comprometer su estabilidad financiera.

8.  **BMAL (Beneficio Medio por Año Luz)**

    -   Justificación: Un alto BMAL indica eficiencia en la operación y rentabilidad sostenible, lo que contribuye a la capacidad de la empresa para reinvertir y mejorar su competitividad.

9.  **IFIDE (Índice de Fidelización)**

    -   Justificación: Un alto nivel de fidelización sugiere que la empresa ha construido relaciones sólidas con sus clientes, lo que le proporciona estabilidad de ingresos y ventajas competitivas a futuro.

Estos indicadores reflejan la capacidad de innovación, estabilidad financiera, expansión de mercado y eficiencia operativa de las empresas, factores esenciales para su sostenibilidad en el tiempo y preparación para los desafíos futuros.

De entre ellas, *Korp* ha seleccionado **IDIVERSE**, **IFIDE** e **IDIG** como aspectos que le importan especialmente. Aun así, su equipo sabe que su jefe quiere una respuesta precisa. Un nombre de una empresa.

Así, el equipo ha pensado en crear un *ranking* de compañías basándose en estos tres indicadores. Pero, si tienen 3 variables, ¿cómo combinar su análisis para obtener un solo *ranking* de modo objetivo? ¿Cómo ponderar las tres variables?

La respuesta ha venido al comprobar que las tres variables guardan entre sí unas correlaciones relativamente altas (en valor absoluto). Es decir: aportan una información bastante parecida sobre cada una de las empresas de la selección. Esto es importante porque, si en gran medida comparten información "redundante", pueden ser, seguramente, "resumidas" en un solo indicador, cuyo valor o puntuación para cada caso (empresa) podría servir para establecer el ranking de compañías candidatas a ser adquiridas.

El método para obtener este indicador a partir de las tres variables originales se llama ***Análisis de Componentes Principales*** **(PCA)**, y puede ser fácilmente desarrollado con unas líneas de código de R. Ese indicador, que es la clave de toda la estrategia, será la primera "componente" del PCA, una combinación lineal de las tres variables originales; siempre y cuando su poder para "retener" la información global ofrecida por esas tres variables sea lo suficientemente alto.

## ![](figuras/pie-chart.svg){.hicon} Preparación previa de datos.

Vamos a suponer que trabajamos dentro de un **proyecto** que hemos creado previamente, de nombre **"componentes"**. Dentro de la carpeta del proyecto guardaremos estos dos elementos:

-   El *script* llamado "componentes_rstars.R".

-   El archivo de Microsoft® Excel® llamado "interestelar_100.xlsx". Si abrimos este último archivo, comprobaremos que se compone de tres hojas. La primera muestra un mensaje sobre el uso de los datos, la segunda recoge la descripción de las variables consideradas, y la tercera (hoja "Datos") almacena los datos que debemos importar. Estos datos se corresponden con diferentes variables económicas y financieras de 104 empresas dedicadas a los servicios de transporte interestelar de mercancías.

Comenzaremos a ejecutar el código usual en cualquier *script*, esto es, limpiar el *Global Environment*, cargar los paquetes necesarios, importar los datos del archivo de Excel®, y tratar los casos con datos faltantes o *missing values*, y los casos que, para las variables estudiadas, se comportan como *ouliers*. En cuanto a los primeros pasos, tenemos:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
### Análisis de Componentes Principales ###

# Limpiando el Global Environment
rm(list = ls())

# Cargando paquetes
library(readxl)
library(dplyr)
library(visdat)
library(ggplot2)
library(gtExtras)
library (GGally)
library (knitr)
library (kableExtra)
library (patchwork)

## DATOS

# Importando datos desde Excel
interestelar_100 <- read_excel("interestelar_100.xlsx",
                               sheet = "Datos",
                               na = c("n.d."))
interestelar_100 <- data.frame(interestelar_100, row.names = 1)

# Seleccionando variables metricas para el analisis.
seleccion <- interestelar_100 %>%
  select(IDIVERSE, IFIDE, IDIG)
seleccion_df_graph <- gt_plt_summary(seleccion)
seleccion_df_graph
```

Básicamente, en el código anterior se han almacenado los datos de la hoja de cálculo en el *data frame* "interestelar_100". Luego, se ha creado un nuevo *data frame* más reducido con las únicas variables del análisis que vamos a realizar (IDIVERSE, IFIDE e IDIG), al que hemos llamado "seleccion". Estas tres variables han sido exploradas a traves de una tabla gráfica a partir de la función `gt_plt_summary()` del paquete `{gtExtras}`.

El siguiente consistirá en localizar los posibles ***missing values***, ya que para obtener componentes principales es necesario que todos los casos posean dato en todas las variables del análisis. Para tener una idea general, se puede utilizar la función `vis_miss()` del paquete `{visdat}`, que localizará gráficamente los *missing values* de las diferentes variables, y calculará el porcentaje de casos que supone, con respecto al total de observaciones:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Localizando missing values.
seleccion %>%
  vis_miss() +
  labs(title = "Indicadores: Diversificación, Fidelidad, Digitalización",
       subtitle = "Transporte de mercancías interestelar",
       y = "Observación",
       fill = NULL) +
  scale_fill_manual(
    values = c("TRUE" = "red", "FALSE" = "grey"),
    labels = c("TRUE" = "NA", "FALSE" = "Presente")) +
  theme(
    plot.title = element_text(face = "bold", size = 14))
```

Del gráfico anterior se desprende que existen 2 *missing values* repartidos en 2 de las 3 variables del estudio. Para localizarlos, podemos filtrar nuestro *data frame* con las herramientas de `{dplyr}`:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
seleccion %>% filter(is.na(IDIVERSE) |
                     is.na(IFIDE) |
                     is.na(IDIG)) %>%
              select(IDIVERSE, IFIDE, IDIG)
```

Los casos con datos faltantes son las empresas *Ezra Bridger Haulage* y *Alderaan Freight*.

Ante la existencia de *missing values*, se puede actuar de varios modos. Por ejemplo, **se puede intentar obtener el conjunto de valores que no están disponibles por otro canal de información,** o recurrir **a alguna estimación**. En caso de que esto sea difícil, se puede optar, simplemente, por **eliminar** estos casos, en especial cuando representan un porcentaje muy reducido respecto al total de observaciones. En nuestro ejemplo, supondremos que hemos optado por esta última vía, y eliminaremos estos casos con el código:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
seleccion <- seleccion %>%
             filter(! is.na(IDIVERSE) &
                    ! is.na(IFIDE) &
                    ! is.na(IDIG))
```

Verificamos en el *Global Environment* que el *data frame* “seleccion” ha pasado a tener 102 casos.

Por otro lado, la técnica de componentes principales **es muy sensible a la existencia de *outliers***. En concreto, las observaciones atípicas pueden afectar a los resultados a través de tres vías:

- **Distorsión de las componentes principales:** pueden influir en la dirección de las componentes principales, haciendo que estas se ajusten más a los valores atípicos que a la mayoría de los datos. Esto puede llevar a una interpretación incorrecta de las relaciones entre las variables.

- **Afectación a las cargas de las variables:** estas cargas son relevantes porque indican la importancia relativa de cada variable original en la formación de la componente, es decir, cuánto contribuye o se correlaciona una variable específica con una componente principal.

- **Modificación de la varianza explicada:** pueden *inflar* la varianza total de los datos, lo que puede afectar a la proporción de varianza explicada por cada componente principal. Esto puede ocasionar una selección incorrecta del número de componentes a retener.

En consecuencia, deberán ser identificados y, en su caso, eliminados. Para realizar este proceso, y dado que en nuestro análisis contamos con 4 variables, primero “resumiremos” el valor que toman dichas variables para cada observación (empresa), mediante el cálculo de la *distancia de Mahalanobis*. De hecho, las distancias de los diferentes casos se almacenarán en una nueva columna o variable de nuestro *data frame,* a la que llamaremos MAHALANOBIS:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Identificando y descartando outliers con distancia de Mahalanobis.
seleccion <- seleccion %>%
  mutate(MAHALANOBIS = mahalanobis(as.matrix(.),
                                   center = colMeans(.),
                                   cov    = cov(.)))
```

Dentro de los argumentos de la función `mahalanobis()` incluida en la función `mutate()` hay unos puntos entre paréntesis. Recordemos que estos puntos deben ser añadidos cuando una función no es la primera del operador "*pipe*" (`%>%`), para indicar que las variables de los paréntesis hacen referencia al *data frame* "seleccion" (o, en general, el objeto que fluye a través del "*pipe*").

A continuación, hemos construido un *box-plot* o diagrama de caja de la variable MAHALANOBIS, como si fuera cualquier otra variable, a partir de la función `ggplot()` del paquete `{ggplot2}`:

```{r, eval=TRUE, echo=TRUE, message=FALSE}

ggplot(data = seleccion, map = (aes(y = MAHALANOBIS))) +
  geom_boxplot(fill = "orange") +
  ggtitle("DISTANCIA DE MAHALANOBIS",
          subtitle = "IDIVERSE, IFIDE, IDIG. Empresas TMI.") +
  ylab("MAHALANOBIS")
```

En el gráfico se aprecia que existen, por encima de la caja, varios *outliers*. Para identificarlos de modo concreto, hemos de calcular los cuartiles primero y tercero de la variable MAHALANOBIS y pasar el correspondiente filtro:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
Q1M <- quantile (seleccion$MAHALANOBIS, c(0.25))
Q3M <- quantile (seleccion$MAHALANOBIS, c(0.75))

seleccion %>%
  filter(MAHALANOBIS > Q3M + 1.5*IQR(MAHALANOBIS) |
           MAHALANOBIS < Q1M - 1.5*IQR(MAHALANOBIS))%>%
  select(MAHALANOBIS, IDIVERSE, IFIDE, IDIG) 
```

Las compañías que se comportan como *outliers*, considerando conjuntamente las tres variables (a través de la distancia de Mahalanobis), son 13. La eliminación de estos casos puede realizarse fácilmente con el código:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Creando nuevo df sin outliers.
seleccion_so <- seleccion %>%
  filter(MAHALANOBIS <= Q3M + 1.5*IQR(MAHALANOBIS) &
           MAHALANOBIS >= Q1M - 1.5*IQR(MAHALANOBIS))  

# Eliminando variable MAHALANOBIS de los df
seleccion    <- seleccion    %>% select(-MAHALANOBIS)
seleccion_so <- seleccion_so %>% select(-MAHALANOBIS)
```

Se ha creado un nuevo *data frame* llamado "seleccion_so” con los casos (89) que **no** son *outliers* (y que no contienen *missing values*), y se ha eliminado la variable MAHALANOBIS, puesto que su única utilidad era la de localizar y filtrar los *outliers*. Con este *data frame* “seleccion_so” es con el que se procederá al cálculo de las componentes.

## ![](figuras/pie-chart.svg){.hicon} Cálculo de componentes.

La **condición previa** para el **cálculo de componentes** es que las variables originales del análisis contengan información redundante, es decir, que en buena medida tengan una capacidad para diferenciar a los casos (empresas) parecida. Esto se verifica con la existencia de **altas correlaciones**, en valor absoluto, entre ellas (al menos, entre *algunas*). Por tanto, hemos de calcular la matriz de correlaciones correspondiente. Un modo gráfico visualmente efectivo es utilizar las posibilidades que nos ofrece el paquete `{GGally}`, mediante la función `ggpairs()`:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Correlaciones.
corr_plot_so <- ggpairs(seleccion_so, 
                        lower = list(continuous = wrap("cor",
                                                       size = 4.5,
                                                       method = "pearson",
                                                       stars = TRUE)),
                        title = "Matriz de Correlación (sin outliers).")
corr_plot_so
```

Puede apreciarse cómo existen altas correlaciones (en valor absoluto) entre todas las variables. Por tanto, tiene sentido hacer un análisis de componentes principales, ya que hay variables que parecen **compartir información**.

La obtención de las componentes se va a realizar mediante la función `prcomp()` del paquete `{stats}`, que es un paquete cargado por defecto al abrir R. Es conveniente que activemos el argumento `scale =` con “T” (*true*) para que las variables originales sean consideradas en sus **versiones tipificadas**. Vamos a asignar los resultados a un objeto de nombre, por ejemplo, “componentes”. Por último, guardaremos el `summary()` o resumen de los resultados con un nombre provisional, por ejemplo, "temporal". El código es el siguiente:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Obtencion de componentes.
componentes <- prcomp (seleccion_so, scale=T)
temporal <- summary (componentes)
temporal
```

La “*Standard deviation*” es la raíz cuadrada de los autovalores asociados a cada componente. “*Proportion of Variance*” nos dice la proporción de la suma de varianzas de las variables originales (*comunalidad*) recogida por cada componente, proporción que se acumula en “*Cumulative Proportion*”. Nótese que las componentes aparecen ordenadas de más a menos importantes en función de la cantidad de varianza que capturan.

En este caso, a partir de la tabla anterior podemos destacar que la primera componente recoge más del 71% de la varianza (*comunalidad*) o información puesta en juego globalmente por las tres variables originales. Las dos primeras componentes, en conjunto, aglutinan casi el 89% de la información de las tres variables ofrecen sobre el comportamiento de las empresas. Entre las tres componentes, lógicamente se recoge el 100% de la *comunalidad* o varianza global.

Si el elemento "*importance*" del `summary()` o resumen "temporal" lo convertimos en un *data frame*, por ejemplo "summary_df", podremos presentar los resultados por medio de una tabla estéticamente más atractiva, a partir de la función `kable()` del paquete `{knitr}`, y las funciones complementarias del paquete `{kableExtra}`:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
# Convertir el resumen en un data frame
summary_df <- as.data.frame(temporal$importance)
summary_df <- t(summary_df)  # Transponer para mejor visualización
rm (temporal)

# Crear la tabla con kable y personalizarla con kableExtra
summary_df %>%
  kable(caption = "Resumen de Componentes",
        col.names = c("Componente", 
                      "Desv. típica",
                      "Proporción de varianza (comunalidad)",
                      "Proporción de varianza (comunalidad) acumulada"),
        digits = c(2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "condensed"),
                full_width = F, 
                position = "center") %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(summary_df)), bold= F, align = "c") %>%
  column_spec(1, bold = TRUE, extra_css = "text-align: center;")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# Convertir el resumen en un data frame
summary_df <- as.data.frame(temporal$importance)
summary_df <- t(summary_df)  # Transponer para mejor visualización
rm (temporal)

# Crear la tabla con kable y personalizarla con kableExtra
library (knitr)
library (kableExtra)
tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
summary_df %>%
  kable(caption = "Resumen de Componentes",
        col.names = c("Componente", 
                      "Desv. típica",
                      "Proporción de varianza (comunalidad)",
                      "Proporción de varianza (comunalidad) acumulada"),
        digits = c(2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "condensed"),
                full_width = F, 
                position = "center") %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(summary_df)), bold= F, align = "c") %>%
  column_spec(1, bold = TRUE, extra_css = "text-align: center;")
}else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
summary_df %>%
  kable(caption = "Resumen de Componentes",
        col.names = c("Componente", 
                      "Desv. típica",
                      "Proporción de varianza (comunalidad)",
                      "Proporción de varianza (comunalidad) acumulada"),
        digits = c(2, 2, 2),
        format.args = list(decimal.mark = ".", scientific = FALSE)) 
}  
```

Los coeficientes o **cargas** de cada componente se obtienen pidiendo a nuestro objeto “*componentes*” el elemento “*rotation*”. Estas cargas las vamos a guardar en un nuevo objeto que llamaremos, por ejemplo, “cargas”, que presentaremos mediante una pequeña tabla diseñada con la función `kable()` del paquete `{knitr}` y otras funciones del paquete `{kableExtra}`:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
# Cargas de cada componente.
cargas <- componentes$rotation
cargas %>%
  kable(caption = "Cargas de las componentes obtenidas",
        digits = c(3, 3, 3),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = c("striped", "bordered", "condensed"),
                position = "center") %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(cargas)), bold= F, align = "c") %>%
  column_spec(1, bold = TRUE, extra_css = "text-align: left;")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# Cargas de cada componente.

cargas <- componentes$rotation
tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
cargas %>%
  kable(caption = "Cargas de las componentes obtenidas",
        digits = c(3, 3, 3),
        format.args = list(decimal.mark = ".", scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = c("striped", "bordered", "condensed"),
                position = "center") %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(cargas)), bold= F, align = "c") %>%
  column_spec(1, bold = TRUE, extra_css = "text-align: left;")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
cargas %>%
  kable(caption = "Cargas de las componentes obtenidas",
        digits = c(3, 3, 3),
        format.args = list(decimal.mark = ".", scientific = FALSE))
}
```

En la tabla, se muestran las cargas (*loads*), que son los coeficientes que intervienen en las combinaciones lineales que definen cada componente, a partir de las variables originales (tipificadas). Por tanto, con base en las cargas se pueden explicitar las ecuaciones correspondientes a cada componente. Por ejemplo, para la primera componente, la ecuación será:

$$
\text{CP}_{i1} = 0.6006 \cdot \text{IDIVERSE}_{i1} + 0.5442 \cdot \text{IFIDE}_{i1} + 0.5858 \cdot \text{IDIG}_{i1}
$$

Puede observarse que, en cuanto a la primera componente, que es la que especialmente nos interesa como *indicador* de la "preparación de las diferentes compañías de transporte para afrontar el futuro", las 3 cargas tienen signo positivo, lo que implica que, cuanto mayores sean los valores de una empresa en las variables **IDIVERSE** (*índice de diversificación*), **IFIDE** (*índice de fidelidad*) e **IDIG** (*índice de digitalización*), mayor será el valor del indicador y, por tanto, su preparación. Además, como las variables fueron tipificadas, los valores de las cargas son comparables. De este modo, vemos cómo, dentro de la primera componente, que es la que adoptamos como indicador, la mayor importancia la tiene **IDIVERSE**, seguido de **IDIG** y, por último, **IFIDE**.

## ![](figuras/pie-chart.svg){.hicon} Retención de componentes.

La etapa de retención de componentes consiste en decidir cuántas de las componentes generadas (recordemos que, en un principio, se calculan tantas componentes como variables originales) consideramos que resumen de un modo aceptable la información contenida en las variables originales. Estas **componentes "retenidas" se convertirán en las componentes principales**.

La primera componente siempre es retenida y, por tanto, es una "componente principal". El resto, que van capturando proporciones cada vez menores de la varianza común de las variables originales (*comunalidad*), podrán o no retenerse; aunque, siempre, la retención de una componente implica que se han retenido todas las anteriores. En este caso práctico, buscamos un único indicador de la "preparación de las diferentes compañías de transporte para afrontar el futuro", por lo que solo vamos a "retener" la primera componente. En otras aplicaciones, podría ser necesario retener varias para recoger la suficiente comunalidad.

Hay varios procedimientos o criterios para decidir cuántas componentes retener. Uno de ellos, comúnmente aplicado, es el de **retener aquellas componentes cuyo autovalor es mayor que 1** (suponiendo que se ha trabajado con las variables en sus versiones tipificadas). Los autovalores son el cuadrado de los elementos “Desviación típica” (valores “*Standard deviation*” (sdev) del objeto “componentes” que hemos generado a partir de la función `prcomp()`).

Hemos creado un *data frame* con estos autovalores calculados (y su orden de importancia, al que hemos llamado variable o columna “orden”, y que es un vector de números enteros consecutivos que va desde uno hasta número de variables originales o de componentes) y los hemos dispuesto en un gráfico de barras:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Determinacion Componentes a retener.
# Criterio del Autovalor mayor que 1.
orden <- c(1:ncol(seleccion_so))
autovalor <- componentes$sdev^2
autovalores <- data.frame(orden, autovalor)

autograph <- ggplot(data = autovalores, map = (aes(x = orden,
                                                   y = autovalor))) +
             geom_bar(stat = "identity",
                      colour = "red",
                      fill = "orange",
                      alpha = 0.7) +
             scale_x_continuous(breaks=c(1:nrow(autovalores)))+
             geom_hline(yintercept = 1,
                        colour = "dark blue") +
             geom_text(aes(label = round(autovalor,2)),
                       vjust = 1,
                       colour = "dark blue",
                       size = 3) +
             ggtitle("AUTOVALORES DE LAS COMPONENTES",
                     subtitle = "Empresas TMI") +
             xlab ("Número de componente") +
             ylab("Autovalor")

autograph
```

Respecto al gráfico, conviene recordar que, al ser de barras, si no se quieren representar las frecuencias sino los valores que toma una variable (en este caso, “autovalor”) para cada valor de la otra variable (en este caso, “orden”); en el `geom_bar()` habrá que añadir el argumento `stat =` con el valor “identity”. Además, se utiliza el elemento `scale_x_continuous()` para pesonalizar la escala del eje x, y que se divida dicho eje en tantos tramos como componentes hay.

En el gráfico obtenido, las componentes cuyas barras atraviesan la línea que pasa por el valor "1" son las que deberían ser retenidas, ya que son las componentes que resumen de modo suficiente la información ofrecida sobre el comportamiento de los casos por las variables originales. En este caso, basta con retener solo la primera componente (por lo tanto, solo contamos con una **componente principal**). Este es un resultado favorable cara a nuestro propósito, ya que nos indica que podemos usar como indicador solo una componente, la primera, y con ella resumiremos suficientemente las tres variables originales. Por tanto, es un buen indicador, en ese sentido.

Un gráfico complementario útil es el que muestra, para cada componente, el porcentaje de varianza total (comunalidad) acumulada al ir reteniendo las sucesivas componentes, un resultado que ya se obtuvo anteriormente en forma de tabla:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
# Comunalidad acumulada.
autovalores <- autovalores %>%
  mutate(variacum = 100*(cumsum((autovalor/nrow(autovalores)))))
checkcp <- ifelse(autovalores$autovalor >= 1, "CP", "NCP")
checkcp
             
vacumgraph <- ggplot(data = autovalores, map = (aes(x = orden,
                                                    y = variacum))) +
              geom_bar(stat = "identity",
                       aes(fill = checkcp),
                       colour = "red",
                       alpha = 0.7) +
              scale_x_continuous(breaks=c(1:nrow(autovalores)))+
              geom_text(aes(label = round(variacum,2)),
                        vjust = 1,
                        colour = "dark blue",
                        size = 3) +
              ggtitle("COMUNALIDAD ACUMULADA POR COMPONENTES",
                      subtitle = "Empresas TMI") +
              xlab ("Número de componente") +
              ylab("Varianza acumulada")
vacumgraph
```

Para obtener el gráfico anterior, se comienza añadiendo al *data frame* “autovalores” una columna o variable que es la *suma acumulada del porcentaje de comunalidad* recogido por las sucesivas componentes, que están ordenadas de mayor a menor autovalor. Para calcular el porcentaje, se usa la función `cumsum()`, y se tiene en cuenta que, como las variables fueron tipificadas para calcular las componentes, la *comunalidad*, que coincide con la suma de las varianzas de las componentes (autovalores), es igual al número de variables o componentes (valor que toma la función `nrow()`).

Después, se ha creado un vector que contiene tantos elementos como variables o componentes hay en el análisis (vector “checkcp”). Con la función condicional `ifelse()` se consigue que los elementos de "checkcp" sean "CP" o "NCP" según los correspondientes autovalores sean mayores o no que 1. Finalmente, según sea el valor de cada elemento de "checkcp", las barras del gráfico se colorearán de uno u otro modo.

Posteriormente, mediante el paquete `{patchwork}`, se han unido los dos gráficos creados en esta fase, poniendo uno debajo del otro:

```{r, eval=TRUE, echo=TRUE, message=FALSE}
combinado <- autograph / vacumgraph
combinado <- combinado + 
  plot_annotation(
    title = "Retención de componentes (Autovalor >1)",
    subtitle = "Empresas TMI (sin outliers)",
    theme = theme(
      # TÍTULO de la composición
      plot.title = element_text(
        size = 16,          # tamaño
        face = "bold",      # negrita
      ),
      # SUBTÍTULO de la composición
      plot.subtitle = element_text(
        size = 12
      )))
combinado
```

Un a vez confirmado el hecho de que la primera componente es suficiente para contar con un buen indicador de "preparación de las diferentes compañías de transporte para afrontar el futuro", considerando los aspectos de *digitalización*, *diversificación* y *fidelización* de clientes, pasaremos a estudiar qué casos concretos ofrecen mejores (mayores) valores en el indicador, para lo cual hemos de calcular sus puntuaciones.

## ![](figuras/pie-chart.svg){.hicon} Puntuaciones de los casos (scores).

Para obtener las puntuaciones de cada caso (empresa) en el indicador de "preparación de las diferentes compañías de transporte para afrontar el futuro" (y que es nuestra componente principal, que a su vez coincide con la primera componente), simplemente debemos tener en cuenta que tales puntuaciones están guardadas en la matriz “x” del objeto `prcomp()` creado. Vamos a renombrar a las primera columna (componente) de esta matriz como “scores” y vamos a recolocar las filas (empresas) de mayor a menor valor de la puntuación (lo que se consigue mediante la función `arrange()` del paquete `{dplyr}`. Finalmente, mostraremos en una tabla el *ranking* de las 10 mejores empresas (según sus puntuaciones en el indicador), "cortando" el *data frame* con la función `slice()`:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
## Puntuaciones o Scores
scores <- componentes$x[,1]  #tantas columnas como componentes retenidas
scores_df <- as.data.frame(scores)
scores_df <- cbind(scores_df,seleccion_so)
scores_top10 <- scores_df %>%
  arrange(desc(scores)) %>%
  slice(1:10)

scores_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, sin outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                                    "bordered",
                                    "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
## Puntuaciones o Scores
scores <- componentes$x[,1]  #tantas columnas como componentes retenidas
scores_df <- as.data.frame(scores)
scores_df <- cbind(scores_df,seleccion_so)
scores_top10 <- scores_df %>%
  arrange(desc(scores)) %>%
  slice(1:10)
  
tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
scores_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, sin outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                                    "bordered",
                                    "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
scores_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, sin outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE))
}
```

De la tabla y gráfico anteriores podemos concluir que las empresas más preparadas para afrontar el futuro, según nuestro indicador (primera componente del análisis PCA) son, por este orden, *Shuttlepod Movers*, *Kamino Movers* e *Ícarus Star Transport*.

¿Seguro?

Este *ranking* se ha elaborado a partir de las compañías que formaron la muestra para realizar el análisis de componentes principales. Estas empresas eran aquellas que tenían dato en las tres variables originales y que **no habían sido calificadas como *outliers***. Los *outliers* se apartaron de la muestra para evitar distorsiones y sesgos en el análisis. Pero una cuestión que podríamos plantearnos es si, una vez calculadas las combinaciones lineales que son las *componentes* sin su influencia, podrían ser ahora, en virtud de esas componentes calculadas, puntuadas. Que una compañía se comporte como *outlier* en una o varias de las variables originales, y no se cuente con ella a la hora de calcular las componentes; no quiere decir necesariamente que no sea una buena candidata a ser la elegida para ser adquirida por su preparación para afrontar el futuro (incluso podría concluirse que en algún aspecto está "especialmente preparada").

```{r, eval=FALSE, echo=TRUE, message=FALSE}
# Scores puntuando outliers
scores_all <- predict(componentes, newdata = seleccion)
scores_all <- scores_all[,1]
scores_all_df <- as.data.frame(scores_all)
scores_all_df <- cbind(scores_all_df,seleccion)
scores_all_top10 <- scores_all_df %>%
  arrange(desc(scores_all)) %>%
  slice(1:10)

scores_all_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, con outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                "bordered",
                "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores_all_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# Scores puntuando outliers
scores_all <- predict(componentes, newdata = seleccion)
scores_all <- scores_all[,1]
scores_all_df <- as.data.frame(scores_all)
scores_all_df <- cbind(scores_all_df,seleccion)
scores_all_top10 <- scores_all_df %>%
  arrange(desc(scores_all)) %>%
  slice(1:10)

tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
scores_all_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, con outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                "bordered",
                "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores_all_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {  
scores_all_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, con outliers)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE))
}
```

Vemos como el *ranking* cambia radicalmente, y pasa a estar encabezado por las compañías ***Arrakis Freight***, ***Chakotay Cargo Systems*** e ***Hyperdrive Express***. Si un análisis particularizado de estas empresas por parte del equipo encargado del estudio da como resultado que sus datos son correctos, serían, seguramente, las candidatas para ser adquiridas por el magnate *Arg-Us Korp*.

## ![](figuras/paperclip.svg){.hicon} Puntuaciones de los casos (scores).

Cabe hacerse una pregunta antes de cerrar esta historia. ¿Qué hubiera ocurrido si se hubieran calculado las componentes sin eliminar los *outliers* previamente? ¿Hubieran cambiado los resultados? ¿era tan relevante el efecto de estos casos sobre los resultados, como comentamos al comienzo del tema, en la parte teórica?

En R, el código es fácil de adaptar: basta con sustituir el *data frame* "seleccion_so" por el *data frame* "seleccion", desde el apartado del cálculo de componentes hasta la formación del primer *ranking* basado en las puntuaciones de las compañías en la primera componente.

El *ranking* obtenido de este modo es el siguiente:

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# Obtencion de componentes (sin eliminación de outliers en cálculo).
componentes2 <- prcomp (seleccion, scale=T)

# Cargas de cada componente.
cargas2 <- componentes2$rotation
## Puntuaciones o Scores
scores2 <- componentes2$x[,1]  #tantas columnas como componentes retenidas
scores2_df <- as.data.frame(scores2)
scores2_df <- cbind(scores2_df,seleccion)
scores2_top10 <- scores2_df %>%
  arrange(desc(scores2)) %>%
  slice(1:10)

tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
scores2_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, outliers en cálculo)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                "bordered",
                "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores2_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {  
scores2_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, outliers en cálculo)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE))
}  
```

Como puede repararse, los cambios, en este caso, no parecen ser relevantes. Solo a partir de la séptima posición se registran cambios en el orden de las empresas.

No obstante, hay una tercera vía para proceder al análisis de componentes principales que nos libera de la necesidad de tener que decidir si es conveniente incluir en el cálculo los *outliers* o no: la utilización de **técnicas robustas**.

## ![](figuras/paperclip.svg){.hicon} Utilización de técnicas robustas: método de Hubert.

La presencia de *outliers*, según comentamos, puede distorsionar los resultados del análisis. Esto se debe, en esencia, a los efectos que estos elementos tienen en el cálculo de *la matriz de varianzas-covarianzas de las variables originales*, básica en el cálculo de componentes. Este efecto se manifiesta, por ejemplo, en un incremento *artificial* de las varianzas, debido a la mayor dispersión inducida por los *outliers*.

En la literatura se han desarrollado métodos de cálculo de esta matriz de varianzas-covarianzas que minimizan este efecto distorsionador de los *outliers*. Son los **métodos robustos**. Este es el caso de la variante del análisis de componentes principales de ***Hubert***, que emplea estimadores robustos de la matriz de varianzas y covarianzas tales como *MCD* o *S-estimators*.

El siguiente código permite obtener las componentes por *Hubert*, y realizar el ranking de empresas de acuerdo a las puntuaciones de la primera componente. Hay que tener en cuenta que, en esta ocasión, las cargas de la primera componente son negativas, luego las mejores compañías en términos de diversificación de operaciones, fidelización de clientes y digitalización serán aquellas que presenten **menores** puntuaciones:

```{r, eval=FALSE, echo=TRUE, message=FALSE}
# --- Obtención de componentes (ROBPCA de Hubert) ---
# "seleccion" debe ser un data.frame/matriz numérica (obs x vars)
library(rrcov)

componentes3 <- PcaHubert(
  x        = seleccion,
  k        = ncol(seleccion),        # 0 => deja que el método elija nº de comp.
  scale    = TRUE,     # estandariza como en prcomp(scale=TRUE)
  mcd      = TRUE,     # fase inicial robusta
)

summary(componentes3)

# --- Cargas de cada componente ---
cargas3 <- as.data.frame(unclass(componentes3@loadings))
cargas3    # Atención! Las cargas de CP1 son negativas: el ranking debe ascender

# --- Puntuaciones (Scores) ---
# Si quieres la 1ª componente (equivalente a componentes2$x[,1]):
scores3 <- as.numeric(componentes3@scores[, 1])
# (Si quieres todas: scores3_all <- as.data.frame(componentes3@scores))

scores3_df <- data.frame(scores3 = scores3) %>%
  cbind(seleccion)

# --- Top-10 por la 1ª componente (orden descendente, como en tu código original) ---
scores3_top10 <- scores3_df %>%
  arrange(scores3_df) %>%      # orden ascendente porque las cargas de PC1 son negativas (mejor empresa => menor puntuación)
  slice(1:10)

scores3_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, Hubert)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                "bordered",
                "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores3_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
# --- Obtención de componentes (ROBPCA de Hubert) ---
# "seleccion" debe ser un data.frame/matriz numérica (obs x vars)
library(rrcov)

componentes3 <- PcaHubert(
  x        = seleccion,
  k        = ncol(seleccion),        # 0 => deja que el método elija nº de comp.
  scale    = TRUE,     # estandariza como en prcomp(scale=TRUE)
  mcd      = TRUE,     # fase inicial robusta
)

summary(componentes3)

# --- Cargas de cada componente ---
cargas3 <- as.data.frame(unclass(componentes3@loadings))
cargas3    # Atención! Las cargas de CP1 son negativas: el ranking debe ascender

# --- Puntuaciones (Scores) ---
# Si quieres la 1ª componente (equivalente a componentes2$x[,1]):
scores3 <- as.numeric(componentes3@scores[, 1])
# (Si quieres todas: scores3_all <- as.data.frame(componentes3@scores))

scores3_df <- data.frame(scores3 = scores3) %>%
  cbind(seleccion)

# --- Top-10 por la 1ª componente (orden descendente, como en tu código original) ---
scores3_top10 <- scores3_df %>%
  arrange(scores3_df) %>%      # orden ascendente porque las cargas de PC1 son negativas (mejor empresa => menor puntuación)
  slice(1:10)

tipo_output <- c("html") # pdf, html, docx
knitr::opts_knit$set(rmarkdown.pandoc.to = tipo_output)

if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
scores3_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, Hubert)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE)) %>%
  kable_styling(full_width = F,
                bootstrap_options = "striped",
                "bordered",
                "condensed",
                position = "center",
                font_size = 12) %>%
  row_spec(0, bold= T, align = "c") %>%
  row_spec(1:(nrow(scores3_top10)),
           bold= F,
           align = "c") %>%
  column_spec(1, bold = TRUE,
              extra_css = "text-align: left;")
} else if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
  scores3_top10 %>%
  kable(caption = "Puntuaciones emporesas TMI (Top-10, Hubert)",
        col.names = c("Empresa",
                      "Puntuación",
                      "I. Diversif.",
                      "I. Fidelizac.",
                      "I. Digitalizac."),
        digits = c(3, 3, 3, 3),
        format.args = list(decimal.mark = ".",
                           scientific = FALSE))
}  
```
En la tabla se comprueba que existen leves variaciones con respecto a las clasificaciones anteriores. A destacar la inclusión en el *top-10* de *Ripley Interestellar Freight*, y la desparición de  *Kamino Movers*.

¿cuál de los 3 ránkings elegirías tú?

## ![](figuras/arrow-down-circle.svg){.hicon} Materiales para realizar las prácticas del capítulo.

En esta sección se muestran los links de acceso a los diferentes materiales (*scripts*, datos...) necesarios para llevar a cabo los contenidos prácticos del capítulo.

**Datos (en formato Microsoft (R) Excel (R)):**

-   interestelar_100.xlsx ([obtener aquí](https://raw.githubusercontent.com/teckel71/RStars-book/main/download/interestelar_100.xlsx))

**Scripts:**

-   componentes_rstars.R ([obtener aquí](https://raw.githubusercontent.com/teckel71/RStars-book/main/download/componentes_rstars.R))
